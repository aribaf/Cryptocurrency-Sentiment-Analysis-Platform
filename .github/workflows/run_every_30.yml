name: Run crypto backend every 30 minutes (safe sequential jobs, logs saved)

# prevent overlapping runs (cancel previous)
concurrency:
  group: crypto-pipeline
  cancel-in-progress: true

on:
  schedule:
    - cron: '*/30 * * * *'   # every 30 minutes
  workflow_dispatch:

jobs:
  # ---------- JOB: Twitter Scrape (runs first) ----------
  twitter:
    runs-on: ubuntu-latest
    timeout-minutes: 45
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with: { python-version: '3.11' }

      - name: Install minimal system deps
        run: |
          sudo apt-get update
          sudo apt-get install -y --no-install-recommends libnss3 libxss1 libgtk-3-0 libgbm1

      - name: Install Python deps (light)
        run: |
          python -m pip install --upgrade pip
          pip install --no-cache-dir selenium pymongo python-dotenv playwright

          # install playwright browsers
          python -m playwright install chromium

      - name: Prepare logs dir
        run: mkdir -p logs

      - name: Write .env from secrets
        env:
          MONGO_URI: ${{ secrets.MONGO_URI }}
          TWITTER_BEARER_TOKEN: ${{ secrets.TWITTER_BEARER_TOKEN }}
        run: |
          echo "MONGO_URI=${MONGO_URI}" > .env
          echo "TWITTER_BEARER_TOKEN=${TWITTER_BEARER_TOKEN}" >> .env
          echo "HEADLESS=true" >> .env

      - name: Run twitter_scraper (one cycle, limited)
        working-directory: ./sentiment_pipeline
        env:
          MAX_TWEETS_PER_TAG: 200   # limit tweets per tag (change if needed)
        run: |
          echo "=== START twitter_scraper_selenium.py ===" > ../logs/twitter.log
          python twitter_scraper_selenium.py >> ../logs/twitter.log 2>&1 || true
          echo "=== END twitter_scraper_selenium.py ===" >> ../logs/twitter.log

      - name: Upload twitter log artifact
        uses: actions/upload-artifact@v4
        with:
          name: twitter-log-${{ github.run_id }}
          path: logs/twitter.log

  # ---------- JOB: Sentiment Analyzer (runs after twitter) ----------
  analyzer:
    runs-on: ubuntu-latest
    needs: twitter
    timeout-minutes: 90
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with: { python-version: '3.11' }

      - name: Install Python packages (CPU torch + transformers)
        run: |
          python -m pip install --upgrade pip
          pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cpu torch torchvision torchaudio --extra-index-url https://pypi.org/simple
          pip install --no-cache-dir transformers pymongo python-dotenv

      - name: Prepare logs dir
        run: mkdir -p logs

      - name: Write .env from secrets
        env:
          MONGO_URI: ${{ secrets.MONGO_URI }}
        run: |
          echo "MONGO_URI=${MONGO_URI}" > .env

      - name: Run sentiment_analyzer (process limited batch)
        working-directory: ./sentiment_pipeline
        env:
          BATCH_SIZE: 64            # number of texts processed at once
          MAX_TWEETS_TO_ANALYZE: 1000  # max tweets to pull/update per run
        run: |
          echo "=== START sentiment_analyzer.py ===" > ../logs/analyzer.log
          python sentiment_analyzer.py >> ../logs/analyzer.log 2>&1 || true
          echo "=== END sentiment_analyzer.py ===" >> ../logs/analyzer.log

      - name: Upload analyzer log artifact
        uses: actions/upload-artifact@v4
        with:
          name: analyzer-log-${{ github.run_id }}
          path: logs/analyzer.log

  # ---------- JOB: Aggregator (runs after analyzer) ----------
  aggregator:
    runs-on: ubuntu-latest
    needs: analyzer
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with: { python-version: '3.11' }

      - name: Install pymongo
        run: |
          python -m pip install --upgrade pip
          pip install pymongo python-dotenv pandas

      - name: Prepare logs dir
        run: mkdir -p logs

      - name: Write .env from secrets
        env:
          MONGO_URI: ${{ secrets.MONGO_URI }}
        run: |
          echo "MONGO_URI=${MONGO_URI}" > .env

      - name: Run sentiment_aggregator (one quick cycle)
        working-directory: ./sentiment_pipeline
        run: |
          echo "=== START sentiment_aggregator.py ===" > ../logs/aggregator.log
          python sentiment_aggregator.py >> ../logs/aggregator.log 2>&1 || true
          echo "=== END sentiment_aggregator.py ===" >> ../logs/aggregator.log

      - name: Upload aggregator log artifact
        uses: actions/upload-artifact@v4
        with:
          name: aggregator-log-${{ github.run_id }}
          path: logs/aggregator.log

  # ---------- JOB: news & reddit automation (runs in parallel/simple) ----------
  other:
    runs-on: ubuntu-latest
    needs: twitter   # optional: run after twitter or remove "needs" to run parallel
    timeout-minutes: 40
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with: { python-version: '3.11' }

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install playwright pymongo python-dotenv

      - name: Run news.py
        working-directory: ./sentiment_pipeline/news
        run: |
          mkdir -p logs
          echo "=== START news.py ===" > ../../logs/news.log
          python news.py >> ../../logs/news.log 2>&1 || true
          echo "=== END news.py ===" >> ../../logs/news.log

      - name: Run automation.py
        working-directory: ./sentiment_pipeline/reddit
        run: |
          echo "=== START automation.py ===" > ../../logs/automation.log
          python automation.py >> ../../logs/automation.log 2>&1 || true
          echo "=== END automation.py ===" >> ../../logs/automation.log

      - name: Upload other logs
        uses: actions/upload-artifact@v4
        with:
          name: other-logs-${{ github.run_id }}
          path: logs
