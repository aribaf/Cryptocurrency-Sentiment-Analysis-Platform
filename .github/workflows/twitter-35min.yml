name: Twitter scrape (every 35m)

on:
  schedule:
    - cron: '*/35 * * * *'
  workflow_dispatch:

jobs:
  twitter:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    env:
      RUN_ONCE: '1'
      MONGO_URI: ${{ secrets.MONGO_URI }}
      PYTHONUNBUFFERED: '1'

    defaults:
      run:
        working-directory: sentiment_pipeline   # ðŸ‘ˆ run inside this folder

    steps:
      - uses: actions/checkout@v4

      - name: Install Google Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y wget gnupg
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo gpg --dearmor -o /usr/share/keyrings/googlechrome.gpg
          echo "deb [arch=amd64 signed-by=/usr/share/keyrings/googlechrome.gpg] http://dl.google.com/linux/chrome/deb/ stable main" | \
            sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: pip-${{ runner.os }}-

      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install selenium pymongo

      - name: Run once (headless)
        env:
          HEADLESS: '1'
        run: |
          echo "Running inside $(pwd)"
          ls -la
          python twitter_scraper_selenium.py
